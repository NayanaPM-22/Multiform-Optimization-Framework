# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TjsYmNBYm7tIKt0X9kcj1Gc0di8kSMlg
"""

# Cell 1
!pip -q install pymoo>=0.6.0 matplotlib numpy

import numpy as np
from dataclasses import dataclass
from typing import Optional, Tuple
from numpy.random import default_rng
from pymoo.core.problem import Problem
from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting
from pymoo.util.misc import vectorized_cdist
from pymoo.operators.crossover.sbx import SBX
from pymoo.operators.mutation.pm import PM
import matplotlib.pyplot as plt

rng = default_rng(1)

@dataclass
class MFOParams:
    base: str = "nsga2"
    pop_size: int = 100
    max_evals: int = 20000
    seed: int = 1
    ref_point: Optional[np.ndarray] = None
    sbx_eta: float = 15.0
    pm_eta: float = 20.0
    transfer_interval: int = 5
    min_k_frac: float = 0.02
    max_k_frac: float = 0.25

# Cell 2
def total_cv(G: np.ndarray) -> np.ndarray:
    if G.size == 0 or G.shape[1] == 0:
        return np.zeros(G.shape[0])
    return np.sum(np.maximum(G, 0.0), axis=1)

def feasible_mask(G: np.ndarray, eps: Optional[np.ndarray]) -> np.ndarray:
    if G.size == 0 or G.shape[1] == 0:
        return np.ones(G.shape[0], dtype=bool)

    if eps is None:
        eps_vec = np.zeros(G.shape[1])
    else:
        eps_vec = eps

    return np.all(G <= eps_vec, axis=1)

def nds_indices(F: np.ndarray) -> np.ndarray:
    if F.size == 0:
        return np.array([])
    return NonDominatedSorting().do(F, only_non_dominated_front=True)

def crowding_distance(F: np.ndarray) -> np.ndarray:
    if len(F) <= 2:
        return np.full(len(F), np.inf)
    cd = np.zeros(len(F))

    for m in range(F.shape[1]):
        sorted_indices = np.argsort(F[:, m])
        cd[sorted_indices[0]] = np.inf
        cd[sorted_indices[-1]] = np.inf

        f_min, f_max = F[sorted_indices[0], m], F[sorted_indices[-1], m]
        if f_max - f_min > 1e-12:
            norm_factor = f_max - f_min
            cd[sorted_indices[1:-1]] += (F[sorted_indices[2:], m] - F[sorted_indices[:-2], m]) / norm_factor
    return cd

def nsga2_survival(F: np.ndarray, n_survive: int) -> np.ndarray:
    nds = NonDominatedSorting()
    survivors = []

    for front in nds.do(F):
        if len(survivors) + len(front) <= n_survive:
            survivors.extend(front)
        else:
            F_front = F[front]
            cd = crowding_distance(F_front)
            order = np.argsort(cd)[::-1]
            survivors.extend(front[order[:n_survive - len(survivors)]])
            break

    return np.array(survivors, dtype=int)

def environmental_selection(X_comb, F_comb, G_comb, n_survive, base, eps_vec=None, ref_point=None):
    cv = total_cv(G_comb)
    feas_mask = feasible_mask(G_comb, eps=eps_vec)
    idx_feas = np.where(feas_mask)[0]
    idx_inf = np.where(~feas_mask)[0]

    X_next, F_next, G_next = [], [], []

    if len(idx_feas) > 0:
        F_feas = F_comb[idx_feas]
        survivor_indices_on_feas = nsga2_survival(F_feas, n_survive)

        X_next.append(X_comb[idx_feas[survivor_indices_on_feas]])
        F_next.append(F_feas[survivor_indices_on_feas])
        G_next.append(G_comb[idx_feas[survivor_indices_on_feas]])

    n_remain = n_survive - len(np.vstack(X_next)) if len(X_next) > 0 else n_survive

    if n_remain > 0 and len(idx_inf) > 0:
        cv_inf = cv[idx_inf]
        order = np.argsort(cv_inf)[:n_remain]

        X_next.append(X_comb[idx_inf[order]])
        F_next.append(F_comb[idx_inf[order]])
        G_next.append(G_comb[idx_inf[order]])

    X_next = np.vstack(X_next)[:n_survive]
    F_next = np.vstack(F_next)[:n_survive]
    G_next = np.vstack(G_next)[:n_survive]

    return X_next, F_next, G_next

def population_diversity(F: np.ndarray) -> float:
    if len(F) <= 1:
        return 0.0
    if F.shape[0] > 1000:
        F = F[np.random.choice(F.shape[0], 1000, replace=False)]

    F_norm = (F - np.min(F, axis=0)) / (np.max(F, axis=0) - np.min(F, axis=0) + 1e-12)
    distances = vectorized_cdist(F_norm, F_norm)
    return np.mean(distances[np.triu_indices(len(F), k=1)])

def epsilon_schedule_init(max_cv_per_constr, T):
    A = max_cv_per_constr
    B = np.zeros_like(A)
    delta = 1.0 / T
    return A, B, delta

def epsilon_at_t(A, B, delta, t, dae_mult=1.0):
    if len(A) == 0:
        return np.zeros(0)
    eps_t = (A - B) * (1.0 - delta * t)**2 + B
    return eps_t * dae_mult

def dae_adjustment(eps_curr, div_curr, div_baseline, slow_factor=0.5, fast_factor=1.2):
    if div_curr > div_baseline:
        mult = fast_factor
    else:
        mult = slow_factor
    return mult

# Cell 3
def reproduce(Xu: np.ndarray, p1_idx: np.ndarray, p2_idx: np.ndarray,
              xl: np.ndarray, xu: np.ndarray,
              sbx: SBX, pm: PM) -> np.ndarray:

    global rng

    p1_idx = np.asarray(p1_idx, dtype=int)
    p2_idx = np.asarray(p2_idx, dtype=int)
    N, D = len(p1_idx), Xu.shape[1]

    parents1 = Xu[p1_idx]
    parents2 = Xu[p2_idx]

    eta_val = getattr(sbx, "eta", 20)
    pc_val = getattr(sbx, "prob", 0.9)
    pm_eta_val = getattr(pm, "eta", 20)

    eta = float(getattr(eta_val, 'value', eta_val))
    pc = float(getattr(pc_val, 'value', pc_val))
    pm_eta = float(getattr(pm_eta_val, 'value', pm_eta_val))

    pm_prob = 1.0 / D

    Xc = np.empty_like(parents1)

    for i in range(N):
        if np.random.rand() <= pc:
            for j in range(D):
                if np.random.rand() <= 0.5:
                    x1, x2 = sorted([parents1[i, j], parents2[i, j]])
                    if abs(x1 - x2) > 1e-14:
                        u = np.random.rand()
                        if u <= 0.5:
                            beta = (2 * u)**(1 / (eta + 1))
                        else:
                            beta = (1 / (2 * (1 - u)))**(1 / (eta + 1))

                        c1 = 0.5 * ((1 + beta) * x1 + (1 - beta) * x2)
                        c2 = 0.5 * ((1 - beta) * x1 + (1 + beta) * x2)

                        c1 = np.clip(c1, xl[j], xu[j])
                        c2 = np.clip(c2, xl[j], xu[j])

                        Xc[i, j] = c1 if np.random.rand() < 0.5 else c2
                    else:
                        Xc[i, j] = x1
                else:
                    Xc[i, j] = parents1[i, j]
        else:
            Xc[i] = parents1[i]

    Xm = np.copy(Xc)

    for i in range(N):
        for j in range(D):
            if np.random.rand() < pm_prob:
                y = Xm[i, j]
                yl, yu = xl[j], xu[j]
                delta1 = (y - yl) / (yu - yl)
                delta2 = (yu - y) / (yu - yl)
                rnd = np.random.rand()
                mut_pow = 1.0 / (pm_eta + 1.)

                if rnd <= 0.5:
                    xy = 1.0 - delta1
                    val = 2.0 * rnd + (1.0 - 2.0 * rnd) * (xy ** (pm_eta + 1))
                    deltaq = (val ** mut_pow) - 1.0
                else:
                    xy = 1.0 - delta2
                    val = 2.0 * (1.0 - rnd) + 2.0 * (rnd - 0.5) * (xy ** (pm_eta + 1))
                    deltaq = 1.0 - (val ** mut_pow)

                y = y + deltaq * (yu - yl)
                Xm[i, j] = np.clip(y, yl, yu)

    return Xm


def knowledge_transfer(A, B, X_t, F_t, G_t, X_s, F_s, G_s) -> Tuple:
    """Adaptive Knowledge Transfer (AKT) from Source to Target."""

    feas_t_mask = feasible_mask(G_t, eps=None)
    X_t_feas = X_t[feas_t_mask]
    F_t_feas = F_t[feas_t_mask]
    nds_s = nds_indices(F_s)
    X_s_nds = X_s[nds_s]
    F_s_nds = F_s[nds_s]
    G_s_nds = G_s[nds_s]
    cv_s_nds = total_cv(G_s_nds)
    order_cv = np.argsort(cv_s_nds)
    div_t = population_diversity(F_t_feas) if len(F_t_feas) > 0 else 0.0
    div_s = population_diversity(F_s)

    if div_t < div_s:
        k_frac = min(params.max_k_frac, params.min_k_frac + (params.max_k_frac - params.min_k_frac) * (div_s - div_t) / div_s)
    else:
        k_frac = params.min_k_frac

    k_frac = np.clip(k_frac, params.min_k_frac, params.max_k_frac)
    k = int(np.round(k_frac * params.pop_size))
    k = min(k, len(X_s_nds))

    if k == 0:
        return X_t, F_t, G_t, X_s, F_s, G_s, k_frac

    X_transfer = X_s_nds[order_cv[:k]]
    F_transfer = F_s_nds[order_cv[:k]]
    G_transfer = G_s_nds[order_cv[:k]]

    feas_t_mask = feasible_mask(G_t, eps=None)
    cv_t = total_cv(G_t)

    rank = np.full(len(X_t), 1e6, dtype=float)
    idx_feas_t = np.where(feas_t_mask)[0]
    idx_inf_t = np.where(~feas_t_mask)[0]

    if len(idx_feas_t) > 0:
        fe_idx_order = nsga2_survival(F_t[idx_feas_t], len(idx_feas_t))
        rank[idx_feas_t[fe_idx_order]] = np.arange(len(idx_feas_t))
    if len(idx_inf_t) > 0:
        cv_inf_t = total_cv(G_t[idx_inf_t])
        order_inf = np.argsort(cv_inf_t)
        rank[idx_inf_t[order_inf]] = len(idx_feas_t) + np.arange(len(idx_inf_t))

    weakest_indices = np.argsort(rank)[-k:]

    X_t_new = np.delete(X_t, weakest_indices, axis=0)
    F_t_new = np.delete(F_t, weakest_indices, axis=0)
    G_t_new = np.delete(G_t, weakest_indices, axis=0)

    X_t_new = np.vstack([X_t_new, X_transfer])
    F_t_new = np.vstack([F_t_new, F_transfer])
    G_t_new = np.vstack([G_t_new, G_transfer])

    return X_t_new, F_t_new, G_t_new, X_s, F_s, G_s, k_frac

# Cell 4
def run_mfo(problem: Problem, params: MFOParams):
    rng_local = default_rng(params.seed)
    n_var, n_obj = problem.n_var, problem.n_obj
    xl = np.array(problem.xl, dtype=float)
    xu = np.array(problem.xu, dtype=float)

    X0 = rng_local.uniform(xl, xu, size=(params.pop_size, n_var))
    out = {}
    problem._evaluate(X0, out)
    F0 = out["F"]
    G0 = out.get("G", np.zeros((len(X0), problem.n_constr))) if problem.n_constr > 0 else np.zeros((len(X0), 0))

    X_t, F_t, G_t = X0.copy(), F0.copy(), G0.copy()
    X_s, F_s, G_s = X0.copy(), F0.copy(), G0.copy()

    if problem.n_constr > 0:
        max_cv_per_constr = np.max(np.maximum(G_s, 0.0), axis=0)
    else:
        max_cv_per_constr = np.zeros((0,))
    T = max(1, params.max_evals // params.pop_size)
    A, B, delta = epsilon_schedule_init(max_cv_per_constr, T=T)

    sbx = SBX(prob=0.9, eta=params.sbx_eta)
    pm = PM(prob=1.0/n_var, eta=params.pm_eta)

    evals = params.pop_size
    gen = 0
    baseline_div_s = population_diversity(F_s) if len(F_s) > 0 else 0.0
    last_k_frac = None

    history = {'gen': [], 'eps_mult': [], 'k_frac': [], 'div_t': [], 'div_s': []}

    while evals < params.max_evals:
        gen += 1
        div_s = population_diversity(F_s)

        dae_mult = dae_adjustment(None, div_s, baseline_div_s, 1.5, 0.8)
        eps_vec = epsilon_at_t(A, B, delta, gen, dae_mult=dae_mult)

        Xu = np.vstack([X_t, X_s])
        Fu = np.vstack([F_t, F_s])
        Gu = np.vstack([G_t, G_s])

        feas_u = feasible_mask(Gu, eps=None)
        idx_feas_u = np.where(feas_u)[0]
        idx_inf_u = np.where(~feas_u)[0]

        rank = np.full(len(Xu), 1e6, dtype=float)
        if len(idx_feas_u) > 0:
            fe_idx_order = nsga2_survival(Fu[idx_feas_u], len(idx_feas_u))
            rank[idx_feas_u[fe_idx_order]] = np.arange(len(idx_feas_u))
        if len(idx_inf_u) > 0:
            cv_inf = total_cv(Gu[idx_inf_u])
            order_inf = np.argsort(cv_inf)
            rank[idx_inf_u[order_inf]] = len(idx_feas_u) + np.arange(len(idx_inf_u))

        def tournament_select(ranks):
            a = rng_local.integers(0, len(ranks))
            b = rng_local.integers(0, len(ranks))
            return a if ranks[a] < ranks[b] else b

        p1 = np.array([tournament_select(rank) for _ in range(params.pop_size)], dtype=int)
        p2 = np.array([tournament_select(rank) for _ in range(params.pop_size)], dtype=int)

        X_off = reproduce(Xu, p1, p2, xl, xu, sbx, pm)

        out_off = {}
        problem._evaluate(X_off, out_off)
        F_off = out_off["F"]
        G_off = out_off.get("G", np.zeros((len(X_off), problem.n_constr))) if problem.n_constr > 0 else np.zeros((len(X_off), 0))
        evals += len(X_off)

        X_t_comb, F_t_comb, G_t_comb = np.vstack([X_t, X_off]), np.vstack([F_t, F_off]), np.vstack([G_t, G_off])
        X_s_comb, F_s_comb, G_s_comb = np.vstack([X_s, X_off]), np.vstack([F_s, F_off]), np.vstack([G_s, G_off])

        X_t, F_t, G_t = environmental_selection(X_t_comb, F_t_comb, G_t_comb, params.pop_size, params.base, eps_vec=None, ref_point=params.ref_point)
        X_s, F_s, G_s = environmental_selection(X_s_comb, F_s_comb, G_s_comb, params.pop_size, params.base, eps_vec=eps_vec, ref_point=params.ref_point)

        k_frac = None
        if gen % params.transfer_interval == 0:
            X_t, F_t, G_t, X_s, F_s, G_s, k_frac = knowledge_transfer(A, B, X_t, F_t, G_t, X_s, F_s, G_s)
            last_k_frac = k_frac

        if gen % 10 == 0 or gen == 1:
            feas_t_mask = feasible_mask(G_t, eps=None)
            div_t = population_diversity(F_t[feas_t_mask]) if np.any(feas_t_mask) else 0.0

            history['gen'].append(gen)
            history['eps_mult'].append(dae_mult)
            history['k_frac'].append(k_frac if k_frac is not None else 0)
            history['div_t'].append(div_t)
            history['div_s'].append(div_s)

    feas_mask_final = feasible_mask(G_t, eps=None)

    if np.any(feas_mask_final):
        F_final = F_t[feas_mask_final]
        X_final = X_t[feas_mask_final]
    else:
        cv_all = total_cv(G_t)
        order = np.argsort(cv_all)
        F_final = F_t[order]
        X_final = X_t[order]

    nd_idx = nds_indices(F_final)

    return X_final[nd_idx], F_final[nd_idx], {'k_frac_last': last_k_frac, 'history': history}

# Cell 5
import numpy as np
from pymoo.indicators.hv import Hypervolume
from pymoo.indicators.igd import IGD
from pymoo.util.misc import vectorized_cdist
from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting

def nds_indices(F: np.ndarray) -> np.ndarray:
    """Helper function for Non-Dominated Sorting, assuming it's available or defined earlier."""
    if F.size == 0:
        return np.array([])
    return NonDominatedSorting().do(F, only_non_dominated_front=True)

def get_true_pf_tnk(n_points=1000):
    """Generates a high-resolution, feasible True Pareto Front for TNK."""

    X_ref = []

    for x1 in np.linspace(0.01, 1.0, n_points):
        x2_g1 = np.sqrt(1.0 + 0.1 * np.cos(16 * np.arctan2(x1, 1e-12)) - x1**2)

        g2_val = (x1 - 0.5)**2 + (x2_g1 - 0.5)**2 - 0.5

        if g2_val <= 0.001:
            X_ref.append([x1, x2_g1])

    F_ref = np.array(X_ref)
    if len(F_ref) == 0:
        return np.array([[]]).reshape(0, 2)

    F_ref = F_ref[np.argsort(F_ref[:, 0])]
    nd_indices = nds_indices(F_ref)
    F_ref = F_ref[nd_indices]

    return F_ref

def calculate_metrics(F_found: np.ndarray, F_ref: np.ndarray, ref_point: np.ndarray):
    """Calculates Hypervolume (HV) and Inverted Generational Distance (IGD)."""

    if len(F_found) == 0:
        return 0.0, np.inf

    hv_indicator = Hypervolume(ref_point=ref_point)
    hv = hv_indicator.do(F_found)

    igd_indicator = IGD(F_ref)
    igd = igd_indicator.do(F_found)

    return hv, igd

# Cell 6
def run_nsga2(problem: Problem, params: MFOParams):
    """Standard NSGA-II algorithm with strict constraint handling (eps=0)."""
    rng_local = default_rng(params.seed)
    n_var = problem.n_var
    xl = np.array(problem.xl, dtype=float)
    xu = np.array(problem.xu, dtype=float)

    X0 = rng_local.uniform(xl, xu, size=(params.pop_size, n_var))
    out = {}
    problem._evaluate(X0, out)
    F0 = out["F"]
    G0 = out.get("G", np.zeros((len(X0), problem.n_constr))) if problem.n_constr > 0 else np.zeros((len(X0), 0))

    X, F, G = X0.copy(), F0.copy(), G0.copy()

    sbx = SBX(prob=0.9, eta=params.sbx_eta)
    pm = PM(prob=1.0/n_var, eta=params.pm_eta)

    evals = params.pop_size

    while evals < params.max_evals:
        feas_mask = feasible_mask(G, eps=None)
        idx_feas = np.where(feas_mask)[0]
        idx_inf = np.where(~feas_mask)[0]

        rank = np.full(len(X), 1e6, dtype=float)

        if len(idx_feas) > 0:
            fe_idx_order = nsga2_survival(F[idx_feas], len(idx_feas))
            rank[idx_feas[fe_idx_order]] = np.arange(len(idx_feas))

        if len(idx_inf) > 0:
            cv_inf = total_cv(G[idx_inf])
            order_inf = np.argsort(cv_inf)
            rank[idx_inf[order_inf]] = len(idx_feas) + np.arange(len(idx_inf))

        def tournament_select(ranks):
            a = rng_local.integers(0, len(ranks))
            b = rng_local.integers(0, len(ranks))
            return a if ranks[a] < ranks[b] else b

        p1 = np.array([tournament_select(rank) for _ in range(params.pop_size)], dtype=int)
        p2 = np.array([tournament_select(rank) for _ in range(params.pop_size)], dtype=int)

        X_off = reproduce(X, p1, p2, xl, xu, sbx, pm)

        out_off = {}
        problem._evaluate(X_off, out_off)
        F_off = out_off["F"]
        G_off = out_off.get("G", np.zeros((len(X_off), problem.n_constr))) if problem.n_constr > 0 else np.zeros((len(X_off), 0))
        evals += len(X_off)

        X_comb, F_comb, G_comb = np.vstack([X, X_off]), np.vstack([F, F_off]), np.vstack([G, G_off])

        X, F, G = environmental_selection(X_comb, F_comb, G_comb, params.pop_size, "nsga2", eps_vec=None)

    feas_mask_final = feasible_mask(G, eps=None)
    if np.any(feas_mask_final):
        F_final = F[feas_mask_final]
        X_final = X[feas_mask_final]
    else:
        cv_all = total_cv(G)
        order = np.argsort(cv_all)
        F_final = F[order]
        X_final = X[order]

    nd_idx = nds_indices(F_final)
    return X_final[nd_idx], F_final[nd_idx]

# Cell 7
import pandas as pd

problem = TNKProblem()
params = MFOParams(
    pop_size=100,
    max_evals=20000,
    seed=42,
    transfer_interval=5
)

print("Generating high-resolution True Pareto Front for metric calculation...")
F_ref = get_true_pf_tnk(n_points=5000)

ideal_point = np.array([0.0, 0.0])
ref_point = np.max(F_ref, axis=0) + 0.1

print("\n--- Running MFO/AKT Algorithm (Novelty) ---")
X_mfo, F_mfo, info_mfo = run_mfo(problem, params)
print(f"MFO: Found {len(F_mfo)} non-dominated feasible solutions.")

print("\n--- Running Baseline NSGA-II Algorithm ---")
X_nsga2, F_nsga2 = run_nsga2(problem, params)
print(f"NSGA-II: Found {len(F_nsga2)} non-dominated feasible solutions.")

hv_mfo, igd_mfo = calculate_metrics(F_mfo, F_ref, ref_point)
hv_nsga2, igd_nsga2 = calculate_metrics(F_nsga2, F_ref, ref_point)

print("\n--- PERFORMANCE COMPARISON (CMOP: TNK) ---")
data = {
    'Algorithm': ['MFO/AKT (Novelty)', 'Baseline (NSGA-II)'],
    'Solutions Found': [len(F_mfo), len(F_nsga2)],
    'Hypervolume (HV) [Diversity]': [f"{hv_mfo:.4f}", f"{hv_nsga2:.4f}"],
    'IGD [Convergence]': [f"{igd_mfo:.4e}", f"{igd_nsga2:.4e}"]
}
df_metrics = pd.DataFrame(data)
print(df_metrics.to_markdown(index=False))

plt.figure(figsize=(9, 7))

plt.plot(F_ref[:, 0], F_ref[:, 1], 'k--', linewidth=2, label='True Pareto Front (Reference)')

plt.scatter(F_mfo[:, 0], F_mfo[:, 1], color='red', s=60, marker='o', label='MFO/AKT Result')

plt.scatter(F_nsga2[:, 0], F_nsga2[:, 1], color='blue', s=60, marker='x', label='Baseline NSGA-II')

plt.xlabel('$f_1$')
plt.ylabel('$f_2$')
plt.title(f'Comparative Pareto Fronts on TNK Problem (HV/IGD Validation)')
plt.legend()
plt.grid(True, linestyle=':', alpha=0.6)
plt.savefig('TNK_Comparative_PF.png')
plt.show()
